## inference推理
深度学习模型包括训练和推理2个过程，训练模型的过程是通过设计神经网络，通过数据训练出模型的参数。而推理则是部署深度学习的过程，实际上目前训练深度学习主要用的是python语言，而部署的时候大部分会采用c++，并且通过gpu进行加速，而inference模块则实现了上述功能。  

inference主要实现了tensorflow, caffe, paddlepaddle3种框架的实现，并且通过cuda进行计算加速。  

#### caffe


#### paddlepaddle


#### tensorrt

